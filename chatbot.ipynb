{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chatbot with past memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x11210e360>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x11210f350>, model_name='gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_api_keys = os.getenv(\"GROQ_API_KEY\")\n",
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model=\"gemma2-9b-It\",api_key=groq_api_keys)\n",
    "model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Siddhant!\\n\\nIt's great to meet you. Being a full-stack developer and a Gen AI student is an exciting combination!  \\n\\nWhat projects are you working on that blend these two areas? I'm always eager to hear about innovative applications of AI in web development. ðŸ˜Š  \\n\\nLet me know if you have any questions about AI or if there's anything I can help you with.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 88, 'prompt_tokens': 27, 'total_tokens': 115, 'completion_time': 0.16, 'prompt_time': 0.00015318, 'queue_time': 0.024311516000000002, 'total_time': 0.16015318}, 'model_name': 'gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-e961c677-0a73-49c8-af20-14b1fe77d57a-0', usage_metadata={'input_tokens': 27, 'output_tokens': 88, 'total_tokens': 115})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "model.invoke([HumanMessage(content=\"hey , i am siddhant  , a full stack developer and gen ai student \")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Yes, I do! You introduced yourself as Siddhant Rathi earlier.  \\n\\nIs there anything I can help you with, Siddhant?\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 93, 'total_tokens': 127, 'completion_time': 0.061818182, 'prompt_time': 0.003459264, 'queue_time': 0.021573723, 'total_time': 0.065277446}, 'model_name': 'gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-566489e5-67e7-4b73-b1ba-c5968466b48d-0', usage_metadata={'input_tokens': 93, 'output_tokens': 34, 'total_tokens': 127})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke([\n",
    "    HumanMessage(content=\"Hello, how are you?and i am siddhant Rathi\"),\n",
    "    AIMessage(content=\"I'm doing well, thank you for asking! How about you?\"),\n",
    "    HumanMessage(content=\"I'm doing well too, thank you!\"), \n",
    "    AIMessage(content=\"You're welcome! It's nice to hear that you're doing well too.\"),\n",
    "    HumanMessage(content=\"do u remember my name?\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "def get_session_history(session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
